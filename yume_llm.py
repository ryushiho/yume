"""yume_llm.py

Phase3: lightweight OpenAI helper for feature-specific generations.

- YumeSpeaker is optimized for short replies tied to an "event".
- Daily rules want a different output format, so we keep a small wrapper here
  while reusing the same persona prompt (yume_prompt.py).

Safety/robustness:
- If OpenAI isn't configured, functions return a deterministic fallback.
- Any exception is caught and returned as a fallback (and should be logged by caller).
"""

from __future__ import annotations

import os
import random
from typing import Any, Optional

from yume_prompt import YUME_ROLE_PROMPT_KR

try:
    from openai import OpenAI  # type: ignore
except Exception:  # pragma: no cover
    OpenAI = None  # type: ignore


_CLIENT: Optional["OpenAI"] = None


def _get_client() -> Optional["OpenAI"]:
    global _CLIENT

    api_key = os.getenv("OPENAI_API_KEY")
    if OpenAI is None or not api_key:
        return None

    if _CLIENT is None:
        _CLIENT = OpenAI(api_key=api_key)  # type: ignore[call-arg]
    return _CLIENT


def _cleanup_text(text: str) -> str:
    t = (text or "").strip()
    if not t:
        return ""

    # Remove surrounding quotes.
    if (t.startswith('"') and t.endswith('"')) or (t.startswith("â€œ") and t.endswith("â€")):
        t = t[1:-1].strip()

    # If model returned multi-line, keep the first meaningful line.
    lines = [ln.strip() for ln in t.splitlines() if ln.strip()]
    if not lines:
        return ""

    # Drop bullets/prefixes.
    t0 = lines[0].lstrip("-â€¢* ").strip()
    return t0


def _cleanup_text_multiline(text: str, *, max_lines: int = 6, max_chars: int = 900) -> str:
    """Keep a few readable lines for menu/poster style outputs."""

    t = (text or "").strip()
    if not t:
        return ""

    # Remove surrounding quotes.
    if (t.startswith('"') and t.endswith('"')) or (t.startswith("â€œ") and t.endswith("â€")):
        t = t[1:-1].strip()

    # Drop empty lines and trim.
    lines = [ln.rstrip() for ln in t.splitlines() if ln.strip()]
    if not lines:
        return ""

    # Remove common bullet prefixes per-line.
    cleaned: list[str] = []
    for ln in lines:
        s = ln.lstrip("-â€¢* ").rstrip()
        if s:
            cleaned.append(s)

    out = "\n".join(cleaned[: max(1, int(max_lines))]).strip()
    if len(out) > int(max_chars):
        out = out[: int(max_chars)].rstrip()
    return out


def generate_text(
    *,
    instructions: str,
    input_text: str,
    max_output_tokens: int = 256,
    model: Optional[str] = None,
) -> str:
    """Generate text via OpenAI Responses API.

    Returns a plain string. If OpenAI isn't configured, returns an empty string.
    """

    client = _get_client()
    if client is None:
        return ""

    m = model or os.getenv("YUME_OPENAI_MODEL", "gpt-4o-mini")

    response = client.responses.create(  # type: ignore[union-attr]
        model=m,
        instructions=instructions,
        input=input_text,
        max_output_tokens=int(max_output_tokens),
    )

    out_items = getattr(response, "output", None) or []
    if not out_items:
        return ""

    message = out_items[0]
    content_list = getattr(message, "content", None) or []
    if not content_list:
        return ""

    text_obj = content_list[0]
    text = getattr(text_obj, "text", None) or ""
    return _cleanup_text(str(text))


def generate_text_multiline(
    *,
    instructions: str,
    input_text: str,
    max_output_tokens: int = 256,
    model: Optional[str] = None,
    max_lines: int = 6,
    max_chars: int = 900,
) -> str:
    """Generate text but keep multiple lines (used for menus/posters)."""

    client = _get_client()
    if client is None:
        return ""

    m = model or os.getenv("YUME_OPENAI_MODEL", "gpt-4o-mini")

    response = client.responses.create(  # type: ignore[union-attr]
        model=m,
        instructions=instructions,
        input=input_text,
        max_output_tokens=int(max_output_tokens),
    )

    out_items = getattr(response, "output", None) or []
    if not out_items:
        return ""

    message = out_items[0]
    content_list = getattr(message, "content", None) or []
    if not content_list:
        return ""

    text_obj = content_list[0]
    text = getattr(text_obj, "text", None) or ""
    return _cleanup_text_multiline(str(text), max_lines=max_lines, max_chars=max_chars)


def generate_daily_rule(
    *,
    date_ymd: str,
    rule_no: int,
    weather_label: str,
    suggestion_hints: list[str] | None = None,
) -> str:
    """Generate a single daily rule line.

    Output should be one line, short, and suitable to embed in a channel announcement.
    """

    hints = suggestion_hints or []
    hint_text = "\n".join([f"- {h}" for h in hints[:3] if h.strip()])

    instructions = (
        YUME_ROLE_PROMPT_KR
        + "\n\n[ì¶œë ¥ ê·œì¹™]"
        + "\n- ì˜¤ëŠ˜ì˜ 'ì•„ë¹„ë„ìŠ¤ êµì¹™'ì„ 1ê°œ ë§Œë“ ë‹¤. (í•œ ì¤„)"
        + "\n- ê¸ì •ì ì´ì§€ë§Œ ì—‰ëš±í•˜ê³ , ì‚¬ë§‰ í•™êµ ëŠë‚Œì´ ë‚˜ì•¼ í•œë‹¤."
        + "\n- ê¸¸ì´ëŠ” 140ì ì´ë‚´. ì´ëª¨ì§€ëŠ” 0~2ê°œ ì •ë„."
        + "\n- AI/ëª¨ë¸/LLM ê°™ì€ ê¸°ìˆ  ì–¸ê¸‰ ê¸ˆì§€."
        + "\n- ê²°ê³¼ëŠ” êµì¹™ ë¬¸ì¥ë§Œ ì¶œë ¥í•œë‹¤. (ë¨¸ë¦¬ë§/í•´ì„¤ ê¸ˆì§€)"
    )

    prompt = (
        f"[ë‚ ì§œ(KST)]: {date_ymd}\n"
        f"[êµì¹™ ë²ˆí˜¸]: ì œ {int(rule_no)}ì¡°\n"
        f"[ì•„ë¹„ë„ìŠ¤ ë‚ ì”¨(ê°€ìƒ)]: {weather_label}\n"
    )

    if hint_text:
        prompt += "\n[ìµœê·¼ êµì¹™ ê±´ì˜(ì°¸ê³ , ê·¸ëŒ€ë¡œ ë³µë¶™ ë§ ê²ƒ)]:\n" + hint_text + "\n"

    prompt += (
        "\nìœ„ ì •ë³´ë“¤ì„ ì°¸ê³ í•´, ì˜¤ëŠ˜ì˜ ì•„ë¹„ë„ìŠ¤ êµì¹™ í•œ ì¤„ì„ ì‘ì„±í•´ë¼.\n"
        "ë¬¸ì¥ë§Œ ì¶œë ¥í•˜ë¼."
    )

    try:
        text = generate_text(instructions=instructions, input_text=prompt, max_output_tokens=128)
        if text:
            return text
    except Exception:
        # Let caller log; return fallback below.
        pass

    # Fallback (no OpenAI / error)
    fallbacks = [
        "ëª¨ë˜ë°”ëŒì´ ë¶ˆ ë•ŒëŠ” ì…ì„ ë²Œë¦¬ê³  'ì•„~' ì†Œë¦¬ë¥¼ ë‚´ì§€ ì•ŠëŠ”ë‹¤! (ì‚¬ë§‰ ê³µê¸°ëŠ” ë©”ë‰´ê°€ ì•„ë‹ˆì•¼~)",
        "ì¶•ì œ í¬ìŠ¤í„°ë¥¼ ë¶™ì¼ ë• í…Œì´í”„ë¥¼ ë‘ ê²¹ìœ¼ë¡œ! (í•œ ê²¹ì€ ëª¨ë˜ê°€ ê°€ì ¸ê°€ë‹ˆê¹Œâ€¦ ì—í—¤í—¤)",
        "ê¸‰ì‹ì´ ê±´ë¹µì´ì–´ë„ ì½”ìŠ¤ ìš”ë¦¬ë¼ê³  ë¯¿ëŠ”ë‹¤! (ë¯¿ìŒì´ ì¹¼ë¡œë¦¬ì•¼~)",
    ]
    return random.choice(fallbacks)


def generate_survival_meal(
    *,
    date_ymd: str,
    base_ingredient: str,
    weather_label: str,
) -> str:
    """Generate a fancy 'imaginary cafeteria menu' for Abydos.

    Output guideline:
    - 2~4 lines
    - Must mention the base ingredient is actually something humble
    - Must sound like Yume (no tech/AI talk)
    """

    instructions = (
        YUME_ROLE_PROMPT_KR
        + "\n\n[ì¶œë ¥ ê·œì¹™]"
        + "\n- ì‚¬ì‹¤ì€ '{base}' ê°™ì€ í—ˆë¦„í•œ ìŒì‹ì´ë‹¤. ì´ê±¸ ìµœê³ ê¸‰ ë ˆìŠ¤í† ë‘ ë©”ë‰´ì²˜ëŸ¼ í¬ì¥í•œë‹¤.".format(
            base=str(base_ingredient)
        )
        + "\n- 2~4ì¤„ë¡œ ì§§ê²Œ. ì²« ì¤„ì€ ë©”ë‰´ ì´ë¦„(ì˜ë¬¸ ëŠë‚Œ + í•œêµ­ì–´ ê´„í˜¸ í•´ì„)ìœ¼ë¡œ, ë‚˜ë¨¸ì§€ëŠ” ì„¤ëª… 1~2ë¬¸ì¥." \
        + "\n- ê³¼ì¥ë˜ì§€ë§Œ ê·€ì—½ê³  í¬ë§ì°¬ í†¤. ì•„ë¹„ë„ìŠ¤/ì‚¬ë§‰/í˜¸ì‹œë…¸ ì§±ì„ ê°€ë” ì–¸ê¸‰í•´ë„ ë¨(í•„ìˆ˜ ì•„ë‹˜)." \
        + "\n- ì´ëª¨ì§€ëŠ” 0~3ê°œ." \
        + "\n- AI/ëª¨ë¸/LLM/í”„ë¡¬í”„íŠ¸ ê°™ì€ ê¸°ìˆ  ì–¸ê¸‰ ê¸ˆì§€." \
        + "\n- ì¶œë ¥ì€ ê²°ê³¼ í…ìŠ¤íŠ¸ë§Œ. ë¨¸ë¦¬ë§/í•´ì„¤/ë²ˆí˜¸ ê¸ˆì§€."
    )

    prompt = (
        f"[ë‚ ì§œ(KST)]: {date_ymd}\n"
        f"[ì•„ë¹„ë„ìŠ¤ ë‚ ì”¨(ê°€ìƒ)]: {weather_label}\n"
        f"[í˜„ì‹¤ ì¬ë£Œ]: {base_ingredient}\n\n"
        "ìœ„ ì •ë³´ë¥¼ ì°¸ê³ í•´ì„œ 'ìƒìƒ ê¸‰ì‹í‘œ' 1ê°œë¥¼ ì‘ì„±í•´ë¼."
    )

    try:
        text = generate_text_multiline(
            instructions=instructions,
            input_text=prompt,
            max_output_tokens=220,
            max_lines=5,
            max_chars=850,
        )
        if text:
            return text
    except Exception:
        pass

    # Fallback
    return (
        "**'Double-Baked Wheat Cracker with Desert Air' (ë‘ ë²ˆ êµ¬ìš´ ê±´ë¹µê³¼ ì‚¬ë§‰ ê³µê¸° ê³ë“¤ì„)**\n"
        "ë°”ì‚­í•¨ì€ í™•ì‹¤í•´! ëª©ì´ ì¢€ ë§‰í ìˆ˜ë„ ìˆì§€ë§Œâ€¦ ê·¸ê²Œ ë˜ ë§¤ë ¥ì´ì§€, ì—í—¤í—¤~ ğŸŒµ"
    )
